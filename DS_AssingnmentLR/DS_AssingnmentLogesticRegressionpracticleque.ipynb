{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fElovXbvReeL",
        "outputId": "b054fc34-9d83-4b0f-9298-c8e6443a2ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "L1 Regularization Accuracy: 0.9666666666666667\n",
            "L2 Regularization Accuracy: 0.9666666666666667\n",
            "Elastic Net Accuracy: 1.0\n",
            "OvR Accuracy: 0.9333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Best Accuracy: 0.9666666666666668\n",
            "Average Accuracy: 0.9733333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from RandomizedSearchCV: {'solver': 'saga', 'penalty': 'l1', 'C': 1000.0}\n",
            "OvO Accuracy: 0.9333333333333333\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Imbalanced Data Accuracy: 0.9666666666666667\n",
            "Accuracy with Scaling: 0.9333333333333333\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multi_class must be in ('ovo', 'ovr')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4256a51470a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# 15. ROC-AUC Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC-AUC Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# 16. Custom Learning Rate (C=0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m             )\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[1;32m    636\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, cohen_kappa_score, matthews_corrcoef\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import joblib\n",
        "\n",
        "# Load dataset (using a sample dataset for demonstration)\n",
        "def load_data():\n",
        "    from sklearn.datasets import load_iris\n",
        "    data = load_iris()\n",
        "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "    df['target'] = data.target\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 1. Basic Logistic Regression\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# 2. L1 Regularization (Lasso)\n",
        "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "lasso_clf.fit(X_train, y_train)\n",
        "print(\"L1 Regularization Accuracy:\", accuracy_score(y_test, lasso_clf.predict(X_test)))\n",
        "\n",
        "# 3. L2 Regularization (Ridge)\n",
        "ridge_clf = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "ridge_clf.fit(X_train, y_train)\n",
        "print(\"L2 Regularization Accuracy:\", accuracy_score(y_test, ridge_clf.predict(X_test)))\n",
        "\n",
        "# 4. Elastic Net Regularization\n",
        "elastic_clf = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "elastic_clf.fit(X_train, y_train)\n",
        "print(\"Elastic Net Accuracy:\", accuracy_score(y_test, elastic_clf.predict(X_test)))\n",
        "\n",
        "# 5. One-vs-Rest Multiclass Classification\n",
        "ovr_clf = LogisticRegression(multi_class='ovr')\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test, ovr_clf.predict(X_test)))\n",
        "\n",
        "# 6. Hyperparameter Tuning using GridSearchCV\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "grid = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n",
        "\n",
        "# 7. Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(clf, X, y, cv=skf)\n",
        "print(\"Average Accuracy:\", np.mean(scores))\n",
        "\n",
        "# 8. Hyperparameter Tuning using RandomizedSearchCV\n",
        "param_dist = {'C': np.logspace(-3, 3, 7), 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "random_search = RandomizedSearchCV(LogisticRegression(), param_dist, cv=5, n_iter=10, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
        "\n",
        "# 9. One-vs-One Multiclass Classification\n",
        "ovo_clf = LogisticRegression(multi_class='ovr')\n",
        "ovo_clf.fit(X_train, y_train)\n",
        "print(\"OvO Accuracy:\", accuracy_score(y_test, ovo_clf.predict(X_test)))\n",
        "\n",
        "# 10. Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "plt.show()\n",
        "\n",
        "# 11. Precision, Recall, F1-Score\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 12. Handling Imbalanced Data with Class Weights\n",
        "weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = dict(enumerate(weights))\n",
        "imbalance_clf = LogisticRegression(class_weight=class_weights)\n",
        "imbalance_clf.fit(X_train, y_train)\n",
        "print(\"Imbalanced Data Accuracy:\", accuracy_score(y_test, imbalance_clf.predict(X_test)))\n",
        "\n",
        "# 13. Titanic Dataset Preprocessing (Example: Handling Missing Values)\n",
        "# df = pd.read_csv(\"titanic.csv\")\n",
        "# df.fillna(df.mean(), inplace=True)  # Handling missing values\n",
        "# Logistic Regression on Titanic dataset\n",
        "\n",
        "# 14. Feature Scaling Impact\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "scaled_clf = LogisticRegression()\n",
        "scaled_clf.fit(X_train_scaled, y_train)\n",
        "print(\"Accuracy with Scaling:\", accuracy_score(y_test, scaled_clf.predict(X_test_scaled)))\n",
        "\n",
        "# 15. ROC-AUC Score\n",
        "y_probs = clf.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_probs))\n",
        "\n",
        "# 16. Custom Learning Rate (C=0.5)\n",
        "custom_clf = LogisticRegression(C=0.5)\n",
        "custom_clf.fit(X_train, y_train)\n",
        "print(\"Custom C Accuracy:\", accuracy_score(y_test, custom_clf.predict(X_test)))\n",
        "\n",
        "# 17. Important Features\n",
        "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': np.abs(clf.coef_).sum(axis=0)})\n",
        "print(feature_importance.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "# 18. Cohen’s Kappa Score\n",
        "print(\"Cohen’s Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
        "\n",
        "# 19. Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n",
        "\n",
        "# 20. Comparing Different Solvers\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    solver_clf = LogisticRegression(solver=solver)\n",
        "    solver_clf.fit(X_train, y_train)\n",
        "    print(f\"Accuracy with {solver}:\", accuracy_score(y_test, solver_clf.predict(X_test)))\n",
        "\n",
        "# 21. Matthews Correlation Coefficient\n",
        "print(\"MCC Score:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "# 22. Model Persistence\n",
        "joblib.dump(clf, \"logistic_model.pkl\")\n",
        "loaded_model = joblib.load(\"logistic_model.pkl\")\n",
        "print(\"Loaded Model Accuracy:\", accuracy_score(y_test, loaded_model.predict(X_test)))\n"
      ]
    }
  ]
}